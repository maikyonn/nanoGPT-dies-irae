{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'I love you but what I do in that role is to make everything in our lives as enjoyable as possible, to allow the individual to choose to make'},\n",
       " {'generated_text': 'I love you guys, I would love to see you on stage in front of a crowd with a bit of passion and show off your own talent on'},\n",
       " {'generated_text': 'I love you, sweetie\", they could have said those words to us. But it\\'s impossible to tell that that was how this story went down'},\n",
       " {'generated_text': 'I love you.\" A girl looked at the boy and smiled her, a simple voice that was still growing and growling.\\n\"I love you'},\n",
       " {'generated_text': \"I love you. I love you and I love you. I really miss you and I still do even though it's taken me more than half to\"}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "set_seed(42)\n",
    "generator(\"I love you\", max_length=30, num_return_sequences=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*May 1, 1945. Berlin, Germany. 12:27 AM*\\n*The closing act of the Second World War was the manifestation of total war such as had never been seen before. No, the term “carnage” would have been more appropriate. Outmanned in every way, Berlin stood in complete isolation, slipping towards the crevice of annihilation. The nearly five hundred thousand troops marching under the banner of the Red Army had already surrounded the capital, making escape virtually impossible. Guns roared, mingling with the screams of the dying in an incessant cacophony of terror as the city was razed and its people massacred.*\\n*Bloodshed. Carnage. All in order to eradicate the enemies of this world, be they young or old, man or woman.*\\n*Justice, revenge, love, peace, oppression, liberty, equality ― the slogan one chose to attach to the horror made little difference. The chaos engulfing the bloody streets demonstrated quite readily the atrocities that would manifest when man was presented with a convenient higher '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('diesirae.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "data = text[:1000]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 6747, 352, 11, 15761, 13, 11307, 11, 4486, 13, 1105, 25, 1983, 3001, 9, 198, 9, 464, 9605, 719, 286, 262, 5498, 2159, 1810]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "tokens = enc.encode(data)\n",
    "print(tokens[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    9,  6747,   352,    11, 15761,    13],\n",
      "        [11307,    11,  4486,    13,  1105,    25],\n",
      "        [ 1983,  3001,     9,   198,     9,   464],\n",
      "        [ 9605,   719,   286,   262,  5498,  2159]])\n",
      "tensor([[ 6747,   352,    11, 15761,    13, 11307],\n",
      "        [   11,  4486,    13,  1105,    25,  1983],\n",
      "        [ 3001,     9,   198,     9,   464,  9605],\n",
      "        [  719,   286,   262,  5498,  2159,  1810]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "buf = torch.tensor(tokens[:24 + 1])\n",
    "x = buf[:-1].view(4, 6)\n",
    "y = buf[1:].view(4, 6)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sheet-music-main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
